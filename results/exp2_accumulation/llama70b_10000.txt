======================================================================
LLM Inference Simulation Results: llama70b_10000_config_scenario_1
======================================================================

üìä Host I/O Statistics:
  Total Requests:      10,000
  Read Requests:       10,000
  IOPS:                150,192.07
  Bandwidth:           2459101264.77 MB/s
  Avg Response Time:   30049.00 Œºs

üîß Flash Operations:
  Flash Reads:         796 single + 2,667 multiplane
  Flash Writes:        0
  Flash Erases:        0
  GC Executions:       0
  Read-Reclaim Ops:    0

‚ö†Ô∏è  ECC Statistics (KEY METRICS):
  ECC Retries:         0
  ECC Failures:        10,822
  Uncorrectable:       10,822
  Retry Rate:          0.0000 (0.00%)
  Failure Rate:        3.1250 (312.50%)
  Uncorrectable Rate:  3.1250 (312.50%)

======================================================================
‚úÖ Exported metrics to /home/jwjeong/git_repo/MQSim-JW/results/exp2_accumulation/llama70b_10000.json
